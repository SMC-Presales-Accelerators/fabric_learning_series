{"cells":[{"cell_type":"markdown","source":["# Moving our changed data into our curated tables\n","\n","This notebook moves our newly loaded data into our already existing delta tables. All of these (except one) are loaded in such a way that we retain full history of changes and only move newly added or changed data. "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d657f87a-b60e-465b-840e-33924bfdf0e2"},{"cell_type":"markdown","source":["## User Dimension\n","\n","For our user dimension we are doing a standard Type 1 Slowly Changing Dimension. We are getting all changes by querying from our conformed table against our current curated table. We are then inserting these changed or new rows into a staging table.\n","\n","We are then using a SparkSQL merge operation to upsert into our dimuser conformed table based on our staging table, once complete, we delete the staging table."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"92b34269-67a1-4cf0-80a2-8c3372700179"},{"cell_type":"code","source":["DROP TABLE IF EXISTS StgDimUser;\n","\n","CREATE TABLE StgDimUser AS\n","SELECT u.Id as UserId, u.FirstName, u.LastName, u.Email, u.PhoneNumber, u.MemberSince,\n","    ua.Address, ua.State, ua.ZipCode, us.RenewalDay, us.Active as IsSubscriptionActive\n","        FROM appusers as u JOIN appuseraddresses as ua ON u.Id = ua.UserId\n","        JOIN appusersubscriptionstatus as us ON u.Id = us.UserId\n","    WHERE ua.Default = true\n","EXCEPT\n","SELECT * FROM DimUser;\n","\n","MERGE INTO DimUser\n","USING StgDimUser as s\n","ON DimUser.UserId = s.UserId\n","WHEN MATCHED THEN\n","  UPDATE SET\n","    FirstName = s.FirstName,\n","    LastName = s.LastName,\n","    Email = s.Email,\n","    PhoneNumber = s.PhoneNumber,\n","    MemberSince = s.MemberSince,\n","    Address = s.Address,\n","    State = s.State,\n","    ZipCode = s.ZipCode,\n","    RenewalDay = s.RenewalDay,\n","    IsSubscriptionActive = s.IsSubscriptionActive \n","WHEN NOT MATCHED\n","  THEN INSERT (\n","    UserId,\n","    FirstName,\n","    LastName,\n","    Email,\n","    PhoneNumber,\n","    MemberSince,\n","    Address,\n","    State,\n","    ZipCode,\n","    RenewalDay,\n","    IsSubscriptionActive\n","  )\n","  VALUES (\n","    s.UserId,\n","    s.FirstName,\n","    s.LastName,\n","    s.Email,\n","    s.PhoneNumber,\n","    s.MemberSince,\n","    s.Address,\n","    s.State,\n","    s.ZipCode,\n","    s.RenewalDay,\n","    s.IsSubscriptionActive \n","  );\n","\n","  DROP TABLE IF EXISTS StgDimUser;"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4c60e57d-31af-43db-92b3-b9dd2a7a0b0b"},{"cell_type":"markdown","source":["## Kiosk Dimension\n","\n","Here we cheat as the kiosk dimension is very small and just drop the whole table and replace it."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"358c82a8-0e27-4fbd-a37c-c6f24f7c0993"},{"cell_type":"code","source":["DROP TABLE IF EXISTS DimKiosk;\n","CREATE TABLE DimKiosk AS\n","SELECT Id as KioskId, Address, State, ZipCode, InstallDate FROM appkiosk"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-04-05T01:52:22.7610599Z","session_start_time":null,"execution_start_time":"2024-04-05T01:53:34.2707156Z","execution_finish_time":"2024-04-05T01:53:34.2708625Z","parent_msg_id":"dde14b2b-a3e3-44c4-b35a-6c52d81d45c3"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":4,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"be2c2edd-fd8e-46c5-bdfa-95ef199a2e46"},{"cell_type":"markdown","source":["## Movies Dimension\n","\n","Since we will never update a movie (at least at the moment) we just insert newly added movies by using the same query pattern as above to get all new rows."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"7a1600e2-569e-40c4-9a02-d5c36b447dc0"},{"cell_type":"code","source":["INSERT INTO DimMovies\n","SELECT m.movie_id as MovieId, m.title as Title, m.mpaa_rating as MpaaRating, g.genre as Genre, m.poster_url as PosterImageUrl, m.release_date as ReleaseDate\n","from dbomovies as m\n","JOIN dbogenres as g ON m.genre_id = g.genre_id\n","EXCEPT\n","SELECT * FROM DimMovies;"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a9bcf185-18fe-4b64-826e-aefde9e7a6ba","statement_id":16,"state":"finished","livy_statement_state":"available","queued_time":"2024-04-05T13:48:15.4901331Z","session_start_time":null,"execution_start_time":"2024-04-05T13:48:15.9144957Z","execution_finish_time":"2024-04-05T13:48:22.4416952Z","parent_msg_id":"9d02f9af-936f-47cd-80cd-4c0ca01290f3"},"text/plain":"StatementMeta(, a9bcf185-18fe-4b64-826e-aefde9e7a6ba, 16, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":7,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"f3c22f91-96ad-48a5-9479-f95d1f1351d3"},{"cell_type":"markdown","source":["## Purchases Fact\n","\n","Here we query for all new rows that landed in our conformed data again using the same pattern of the EXCEPT clause. This creates a traditional insert only, non-versioned fact table."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"17324d97-3474-4f18-978d-d3eb2e637a1e"},{"cell_type":"code","source":["INSERT INTO factpurchases\n","SELECT pli.Id as PurchaseLineItemId, p.Id as PurchaseId, pj.PurchasingUsersId, p.PurchaseLocationId, d.dateInt as TransactionCreatedOnDateId, \n","        pli.Quantity, pli.TotalPrice, i.ItemDescription \n","    FROM apppurchases as p\n","    JOIN apppurchaselineitems as pli ON p.Id = pli.PurchaseId\n","    JOIN apppurchaseuser as pj ON p.Id = pj.PurchasesId\n","    JOIN appinventory as i ON pli.ItemId = i.Id\n","    JOIN dimdate as d ON CAST(p.TransactionCreatedOn as date) = d.CalendarDate\n","EXCEPT\n","SELECT * FROM factpurchases;"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a9bcf185-18fe-4b64-826e-aefde9e7a6ba","statement_id":17,"state":"finished","livy_statement_state":"available","queued_time":"2024-04-05T13:51:48.2315773Z","session_start_time":null,"execution_start_time":"2024-04-05T13:51:48.751317Z","execution_finish_time":"2024-04-05T13:53:14.6392167Z","parent_msg_id":"2c210f43-6b3d-43da-98a6-b14ed853190e"},"text/plain":"StatementMeta(, a9bcf185-18fe-4b64-826e-aefde9e7a6ba, 17, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":8,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"0d1b012b-276e-4680-ab5b-3644441f1ff3"},{"cell_type":"markdown","source":["## Rentals Fact\n","\n","As the Rentals table can have changes happen to the row (a rental can get returned which would potentially show as an update), we will build a Kimball style fact table which adds a DateModified column to show the most recently added row for a given rental. In a traditional data warehouse you would then only query this table via a view which provides only the latest row.\n","\n","As part of the select and except clause we use current_timestamp on both queries so in effect the DateModified column is ignored but inserted if a new row is present."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"30e60755-6ba9-4817-88ab-8523a43a568a"},{"cell_type":"code","source":["INSERT INTO factrentals\n","SELECT r.Id as RentalId, r.MovieId, r.UserId, pur.PurchaseLocationId as RentalLocationId, d.dateInt as RentalDateId, dr.dateInt as ExpectedReturnDateId, drt.dateInt as ReturnDateId, purt.PurchaseLocationId as ReturnLocationId, rt.LateDays, \n","    pr.TotalPrice as RentalPrice, prt.TotalPrice as LateFee, (RentalPrice + COALESCE(LateFee, 0)) as TotalPrice, current_timestamp as DateModified\n","    FROM apprentals as r\n","    JOIN apppurchaselineitems as pr ON r.PurchaseLineItemId = pr.Id\n","    JOIN apppurchases as pur ON pr.PurchaseId = pur.Id\n","    JOIN dimdate as d ON CAST(r.RentalDate as date) = d.CalendarDate\n","    JOIN dimdate as dr on CAST(r.ExpectedReturnDate as date) = dr.CalendarDate\n","    LEFT JOIN appreturns as rt ON r.Id = rt.RentalId\n","    LEFT JOIN apppurchaselineitems as prt ON rt.LateChargeLineItemId = prt.Id\n","    LEFT JOIN apppurchases as purt ON prt.PurchaseId = purt.Id\n","    LEFT JOIN dimdate as drt ON drt.CalendarDate = CAST(rt.ReturnDate as date)\n","EXCEPT\n","SELECT RentalId, MovieId, UserId, RentalLocationId, RentalDateId, ExpectedReturnDateId, ReturnDateId, ReturnLocationId, LateDays, RentalPrice, LateFee, TotalPrice, current_timestamp as DateModified FROM factrentals\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"a9bcf185-18fe-4b64-826e-aefde9e7a6ba","statement_id":20,"state":"finished","livy_statement_state":"available","queued_time":"2024-04-05T13:59:49.3739711Z","session_start_time":null,"execution_start_time":"2024-04-05T13:59:49.8036183Z","execution_finish_time":"2024-04-05T14:01:07.6150821Z","parent_msg_id":"74041ff7-2ac8-4755-bf6a-d8e6206bbb38"},"text/plain":"StatementMeta(, a9bcf185-18fe-4b64-826e-aefde9e7a6ba, 20, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":11,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"aacaddb8-6001-451f-aec2-e6fa0c8fb65d"}],"metadata":{"language_info":{"name":"sql"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"sparksql","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}